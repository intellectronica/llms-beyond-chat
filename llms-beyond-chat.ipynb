{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLMs: Beyond Chat\n",
        "\n",
        "Large Language Models, like GPT-4o, are well known as capabale chatbots, through applications like ChatGPT and Copilot. While chatting with a computer is a magical experience, these models can do some much more than just chat. In this tutorial we'll review some of these capabilities and adopt an approach for working with LLMs that treats them more like an execution engine for software - a VM, by analogy, than a chatty persona. We'll use structured input and ouput, relying on typed schema, to interface between the textual and difficult to predict and control world of LLMs and the realm of software development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-zWHmskQru"
      },
      "source": [
        "## Setting Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRxzoZEYkQrv"
      },
      "source": [
        "### Installing Dependencies\n",
        "\n",
        "We'll need the following Python packages:\n",
        "- `python-dotenv` for loading the endpoint configuration from the .env file\n",
        "- `openai` for making calls to Azure Open AI\n",
        "- `pydantic` and `instructor` for using typed, structured input and output with our LLM calls\n",
        "- `pandas`, `matplotlib`, `networkx`, and `jinja2` to help us visualise our output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5hLfrJGkQrw"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv openai pydantic instructor pandas matplotlib networkx jinja2\n",
        "from IPython.display import clear_output ; clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVV6MCRIkQrw"
      },
      "source": [
        "### Loading Azure Open AI configuration\n",
        "\n",
        "To configure your Azure Open AI GPT-4o endpoint:\n",
        "1. Create a deployment of GPT-4o in one of the [available regions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#public-cloud-regions). Use a \"Global Standard\" deployment to get the best performance. If you prefer to use an earlier model like GPT-4-turbo you can use that too (but it will be slower and more expensive).\n",
        "2. Copy the file `dot.env` to `.env`. Edit it and update the values for `AZURE_OPENAI_ENDPOINT`,`AZURE_OPENAI_API_KEY`, and `GPT_4_O_MODEL_NAME` (that's your deployment name).\n",
        "3. The next cell will load these values and configure the OpenAI SDK to use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2dCRzUxkQrx"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "GPT_4_O_MODEL_NAME = os.getenv(\"GPT_4_O_MODEL_NAME\", default=\"gpt-4o\")\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "aoai = AzureOpenAI(\n",
        "    api_version=\"2024-05-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FAs_fKkQrx"
      },
      "source": [
        "## Using Structured Input/Output with OpenAI\n",
        "\n",
        "To use typed, structured input and output with our LLM calls, we will be relying on `pydantic` and `instructor`.\n",
        "\n",
        "**Pydantic** ( [https://docs.pydantic.dev/](https://docs.pydantic.dev/) ) is a popular package for extending Python's typing system with declerative interfaces.\n",
        "\n",
        "**Instructor** ( [https://python.useinstructor.com/](https://python.useinstructor.com/) ) patches the LLM SDK with the ability to use a Pydantic model for specifying the JSON schema for the LLM output, and parsing the result into the Pydantic mode. We will be using it in all of our examples to interact with our LLM.\n",
        "\n",
        "Let's start by patching our LLM client and defining some helper functions..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "import json\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# `client` is a patched Open AI SDK client that allows passing a Pydantic\n",
        "# model for specifying the schema and parsing the output.\n",
        "client = instructor.from_openai(aoai)\n",
        "\n",
        "# Let's define a helper function for calling the LLM. We will use this\n",
        "# function for all our LLM calls.\n",
        "def llm(response_model: BaseModel = BaseModel, system: str = None,\n",
        "        user: str = None, temperature: float = 0.0, max_tokens: int = 1000):\n",
        "    \"\"\"\n",
        "    Helper function for calling the LLM (GPT-4o) with a Pydantic BaseModel,\n",
        "    a system prompt and/or a user prompt, with temperature and max_tokens.\n",
        "    \"\"\"\n",
        "    messages = []\n",
        "    if system:\n",
        "        messages.append({\"role\": \"system\", \"content\": system})\n",
        "    if user:\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "    result = client.chat.completions.create(\n",
        "        model=GPT_4_O_MODEL_NAME,\n",
        "        response_model=response_model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return result\n",
        "\n",
        "def print_schema(model: BaseModel):\n",
        "    \"\"\"\n",
        "    Print the JSON schema corrsponding to a Pydantic model.\n",
        "    \"\"\"\n",
        "    print(json.dumps(model.model_json_schema(), indent=2))\n",
        "\n",
        "def print_result(result: BaseModel):\n",
        "    \"\"\"\n",
        "    Print the Pydantic model result of an LLM call as JSON.\n",
        "    \"\"\"\n",
        "    print(result.model_dump_json(indent=2))\n",
        "\n",
        "# Configure Pandas to format dataframes for pretty output inside the notebook\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.DataFrame._repr_html_ = lambda df: df.style.set_properties(**{'text-align': 'left'})._repr_html_()\n",
        "\n",
        "def visualize_graph(graph):\n",
        "    \"\"\"\n",
        "    Visualize a graph.\n",
        "    Expects a graph object with `nodes` and `edges` properties,\n",
        "    where each node has an `id`, `label`, and `color`\n",
        "    and each edge has `source`, `target`, `label`, and `color`.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    for node in graph.nodes:\n",
        "        G.add_node(node.id, label=node.label, color=node.color)\n",
        "    for edge in graph.edges:\n",
        "        G.add_edge(edge.source, edge.target, label=edge.label, color=edge.color)\n",
        "    pos = nx.planar_layout(G)\n",
        "    node_colors = [node[1]['color'] for node in G.nodes(data=True)]\n",
        "    edge_colors = [edge[2]['color'] for edge in G.edges(data=True)]\n",
        "    labels = {node[0]: node[1]['label'] for node in G.nodes(data=True)}\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    nx.draw(G, pos, labels=labels, with_labels=True, node_color=node_colors, edge_color=edge_colors, font_size=8)\n",
        "    plt.title(\"Knowledge Graph\")\n",
        "    plt.show()\n",
        "\n",
        "def print_tree(data, indent=0):\n",
        "    \"\"\"\n",
        "    Pretty-print a JSON object as a tree.\n",
        "    \"\"\"\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            print('   ' * indent + key.upper() + ':')\n",
        "            print_tree(value, indent + 1)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            print_tree(item, indent)\n",
        "    else:\n",
        "        print('   ' * indent + str(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQBHip4rkQry"
      },
      "source": [
        "## Working with Text\n",
        "\n",
        "LLMs are master text manipulators. If it's reading or writing text, the best LLMs can do amazing things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translation and Normalization\n",
        "\n",
        "Reading and writing, understanding and translating text between languages, or language styles, is an easy task with LLMs.\n",
        "\n",
        "Let's start by reading a sentence in one language, detecting which language it is, and translating the sentence to English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "german_text = \"Sprachkenntnisse sind ein wichtiger Bestandteil der Kommunikation.\"\n",
        "\n",
        "class TranslatedString(BaseModel):\n",
        "    input_language: str = Field(..., description=\"The language of the original text, as 2-letter language code.\")\n",
        "    translation: str\n",
        "\n",
        "print(\"SCHEMA:\")\n",
        "print_schema(TranslatedString)\n",
        "\n",
        "translation = llm(\n",
        "    TranslatedString,\n",
        "    \"Detect the language of the original text and translate it into English.\",\n",
        "    german_text,\n",
        ")\n",
        "\n",
        "print(\"RESULT:\")\n",
        "print_result(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our LLM can cope with a more complex task. Let's get it to translate the same sentence to multiple languages.\n",
        "\n",
        "Comment on token selection: for many processing tasks we'd want the LLM to be quite conservative with token selection, to get the most accurate results, but when it comes to writing text, it is often better to give it more freedom in selecting tokens from a wider distribution. We can control that by passing a higher `temperature` value when making the call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "english_text = \"Large Language Models are a powerful tool for natural language processing.\"\n",
        "\n",
        "class TargetLanguage(str, Enum):\n",
        "    de = \"de\"\n",
        "    fr = \"fr\"\n",
        "    it = \"it\"\n",
        "    es = \"es\"\n",
        "    he = \"he\"\n",
        "\n",
        "class Translation(BaseModel):\n",
        "    language: TargetLanguage = Field(..., description=f\"The language of the translated text, as 2-letter language code.\")\n",
        "    translation: str\n",
        "\n",
        "class Translations(BaseModel):\n",
        "    translations: List[Translation]\n",
        "\n",
        "print_schema(Translations)\n",
        "\n",
        "translations = llm(\n",
        "    Translations,\n",
        "    f\"Translate the user-provided text into the following languages: {json.dumps([language.value for language in TargetLanguage])}\",\n",
        "    english_text,\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "pd.DataFrame(translations.dict()[\"translations\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as we can translate to different languages, we can also use the format to rewrite text in a different style or tone within the same language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = \"Large Language Models are a powerful tool for natural language processing.\"\n",
        "\n",
        "class TextStyle(str, Enum):\n",
        "    formal = \"formal\"\n",
        "    informal = \"informal\"\n",
        "    casual = \"casual\"\n",
        "    academic = \"academic\"\n",
        "    professional = \"professional\"\n",
        "    business = \"business\"\n",
        "\n",
        "class NormalizedText(BaseModel):\n",
        "    style: TextStyle = Field(..., description=(\"The style of the text normalization.\"))\n",
        "    text: str\n",
        "\n",
        "class NormalizedTexts(BaseModel):\n",
        "    normalized_texts: List[NormalizedText]\n",
        "\n",
        "normalizations = llm(\n",
        "    NormalizedTexts,\n",
        "    f\"Normalize the user-provided text into the following styles: {json.dumps([style.value for style in TextStyle])}\",\n",
        "    input_text,\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "pd.DataFrame(normalizations.dict()[\"normalized_texts\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unstructured Data\n",
        "\n",
        "One very powerful task we can use an LLM for, is parsing unstructured information into a data structure. Addresses, for example, are often found in documents in incosistent formats, and parsing them into a consistent data strcuture can be very useful for using them in a software system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9xib4jBkQrx",
        "outputId": "31c103a7-60d5-4d34-818d-479ddcffbd37"
      },
      "outputs": [],
      "source": [
        "address_str = \"Sherlock Holmes lives in the United Kingdom. His residence is in at 221B Baker Street, London, NW1 6XE.\"\n",
        "\n",
        "class AddressInfo(BaseModel):\n",
        "    first_name: str\n",
        "    last_name: str\n",
        "    street: str\n",
        "    house_number: str\n",
        "    postal_code: str\n",
        "    city: str\n",
        "    state: str\n",
        "    country: str\n",
        "\n",
        "address_info = llm(\n",
        "    AddressInfo,\n",
        "    address_str,\n",
        ")\n",
        "\n",
        "print_result(address_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That was easy! We didn't even have to prompt, just let the LLM know what is the data structure we are expecting. How about a more complex input with multiple addresses? We should be able to get the LLM to process that too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = (\n",
        "  \"During my recent travels, I had the pleasure of visiting several fascinating locations. \"\n",
        "  \"My journey began at the office of Dr. Elena Martinez, 142B Elm Street, San Francisco, \"\n",
        "  \"CA 94107, USA. Her office, nestled in the bustling heart of the city, was a hub of \"\n",
        "  \"innovation and creativity. Next, I made my way to the historic residence of Mr. Hans \"\n",
        "  \"Gruber located at 3. Stock, Goethestrasse 22, 8001 Zürich, Switzerland. The old building, \"\n",
        "  \"with its classic Swiss architecture, stood as a testament to the city’s rich cultural \"\n",
        "  \"heritage. My adventure continued at the tranquil countryside home of Satoshi Nakamoto, \"\n",
        "  \"2-15-5, Sakura-cho, Musashino-shi, Tokyo-to 180-0003, Japan. Their home was surrounded by \"\n",
        "  \"beautiful cherry blossoms, creating a picturesque scene straight out of a postcard. In \"\n",
        "  \"Europe, I visited the charming villa of Mme. Catherine Dubois, 15 Rue de la République, \"\n",
        "  \"69002 Lyon, France. The cobblestone streets and historic buildings of Lyon provided a \"\n",
        "  \"perfect backdrop to her elegant home. Finally, my journey concluded at the modern apartment \"\n",
        "  \"of Mr. David Johnson, Apt 7B, 34 Queen Street, Toronto, ON M5H 2Y4, Canada. The sleek \"\n",
        "  \"design of the apartment building mirrored the contemporary vibe of the city itself.\"\n",
        "  )\n",
        "\n",
        "class Addresses(BaseModel):\n",
        "    addresses: List[AddressInfo]\n",
        "\n",
        "addresses_in_text = llm(\n",
        "    Addresses,\n",
        "    \"Return all the addresses in the user-provided text.\",\n",
        "    input_text,\n",
        ")\n",
        "\n",
        "pd.DataFrame(addresses_in_text.dict()[\"addresses\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The intelligence of LLMs allows them to \"understand\" complex logical and hierarchical structures. Consider the task of converting some information into a knowledge graph. Turning longform text into structure we can work with as part of a system can be of great value, and our LLM can help us achieve that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = (\n",
        "    \"Some products are edible and others are inedible. Soap, newspapers, and shoes, for example, \"\n",
        "    \"are inedible. Of the products that are edible, some are sweet and others are savory. \"\n",
        "    \"Chocolate, candy, and ice cream are sweet, while pizza, burgers, and fries are savory. \"\n",
        "    \"Chocolate comes in different forms, such as milk chocolate, dark chocolate, and white chocolate. \"\n",
        "    \"The New York Times, The Wall Street Journal, and The Washington Post are newspapers.\"\n",
        ")\n",
        "\n",
        "class Node(BaseModel):\n",
        "    id: int\n",
        "    label: str\n",
        "    color: str\n",
        "\n",
        "class Edge(BaseModel):\n",
        "    source: int\n",
        "    target: int\n",
        "    label: str\n",
        "    color: str = \"black\"\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    nodes: List[Node] = Field(..., default_factory=list)\n",
        "    edges: List[Edge] = Field(..., default_factory=list)\n",
        "\n",
        "knowledge_graph = llm(\n",
        "    KnowledgeGraph,\n",
        "    \"Format the information in the user-provided text as a knowledge graph.\",\n",
        "    input_text,\n",
        ")\n",
        "\n",
        "visualize_graph(knowledge_graph)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some structures are recursive. Consider the task of parsing a linguistic sentence into a grammatical tree structure. This NLP task has kept computational linguists busy for decades, often with limited success. LLMs, however, are quite good at this sort of thing. Let's try to get the LLM to parse a simple sentence into a simplified tree grammar of English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_str = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "class NounPhrase(BaseModel):\n",
        "    det: str\n",
        "    adj: List[str]\n",
        "    noun: str\n",
        "\n",
        "class PrepPhrase(BaseModel):\n",
        "    prep: str\n",
        "    noun: NounPhrase\n",
        "\n",
        "class VerbPhrase(BaseModel):\n",
        "    noun: NounPhrase\n",
        "    verb: str\n",
        "    prep: PrepPhrase\n",
        "\n",
        "grammar_tree = llm(\n",
        "    VerbPhrase,\n",
        "    \"Parse the user-provided sentence into a simple grammar tree.\",\n",
        "    input_str,\n",
        ")\n",
        "\n",
        "print_tree(grammar_tree.dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYFPu0w7kQry"
      },
      "source": [
        "## Decision Making\n",
        "\n",
        "We've looked at LLMs reading and, in a way, \"understanding\" information, and rewriting it in useful formats. But the best LLMs also exhibit limited, but nevertheless impressive, reasoning and decision-making capabilities. Let's see how we can exploit them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sentiment Analysis\n",
        "\n",
        "Sentiment analysis, passing a judgement on the tone of a linguistic statement, is a common task that is being used in many systems, especially ones that are user-facing. Without any additional training, our LLM turns out to be quite good at making these judgements. It even can judge its own confidence level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_texts = [\n",
        "    \"I am very happy with the service provided by the company.\",\n",
        "    \"The food was terrible and the service was slow.\",\n",
        "    \"The movie was okay.\",\n",
        "    \"The weather is perfect for a day at the beach.\",\n",
        "    \"I am mostly satisfied with the product, but there are a few issues.\",\n",
        "    \"The experience was note quite what I have expected.\",\n",
        "    \"Butterflies are often colourful, and they can fly.\",\n",
        "]\n",
        "\n",
        "class Sentiment(str, Enum):\n",
        "    positive = \"positive\"\n",
        "    negative = \"negative\"\n",
        "    neutral = \"neutral\"\n",
        "\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    sentiment: Sentiment\n",
        "    confidence: float\n",
        "\n",
        "results = []\n",
        "for example_text in example_texts:\n",
        "    sentiment_analysis = llm(\n",
        "        SentimentAnalysis,\n",
        "        \"Analyze the sentiment of the user-provided text.\",\n",
        "        example_text,\n",
        "    )\n",
        "    results.append({\n",
        "        \"text\": example_text,\n",
        "        \"sentiment\": sentiment_analysis.sentiment.value,\n",
        "        \"confidence\": f\"{sentiment_analysis.confidence * 100:.0f}%\",\n",
        "    })\n",
        "\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification\n",
        "\n",
        "Classification is another task that requires judgement. We want our take several pieces of content and assign them to a class, or multiple tags. We want the LLM to take out taxonomy into consideration, but also make a descision as to which tags would best fit every item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "items = [\n",
        "    {\"title\": \"The Great Gatsby\", \"subtitle\": \"A novel by F. Scott Fitzgerald\"},\n",
        "    {\"title\": \"The Theory of Relativity\", \"subtitle\": \"A scientific theory by Albert Einstein\"},\n",
        "    {\"title\": \"The Technology and Culture of Ancient Rome\", \"subtitle\": \"A cross-disciplinary study of ancient Rome\"},\n",
        "    {\"title\": \"Football on Television\", \"subtitle\": \"The technology and cultural impact of televising football games\"},\n",
        "    {\"title\": \"The Philosophy of Taylor Swift\", \"subtitle\": \"A philosophical analysis of the music and lyrics of Taylor Swift\"},\n",
        "    {\"title\": \"The Spanish Language in popular music\", \"subtitle\": \"A review of the use of the Spanish language in popular music\"},\n",
        "    {\"title\": \"The Impact of Artificial Intelligence on Healthcare\", \"subtitle\": \"Exploring the role of AI in revolutionizing healthcare\"},\n",
        "    {\"title\": \"The History of Jazz Music\", \"subtitle\": \"Tracing the origins and evolution of jazz music\"},\n",
        "    {\"title\": \"The Rise of E-commerce in the Digital Age\", \"subtitle\": \"Examining the growth and impact of online shopping\"},\n",
        "    {\"title\": \"The Art of Photography\", \"subtitle\": \"Exploring the creative and technical aspects of photography\"},\n",
        "    {\"title\": \"The Psychology of Decision Making\", \"subtitle\": \"Understanding the cognitive processes behind decision making\"},\n",
        "    {\"title\": \"The Role of Women in STEM Fields\", \"subtitle\": \"Highlighting the contributions of women in science, technology, engineering, and mathematics\"},\n",
        "    {\"title\": \"The Cultural Significance of Tattoos\", \"subtitle\": \"Exploring the history and symbolism of tattoos in different cultures\"},\n",
        "]\n",
        "\n",
        "\n",
        "class Tag(str, Enum):\n",
        "    literature = \"literature\"\n",
        "    science = \"science\"\n",
        "    history = \"history\"\n",
        "    technology = \"technology\"\n",
        "    art = \"art\"\n",
        "    music = \"music\"\n",
        "    sports = \"sports\"\n",
        "    philosophy = \"philosophy\"\n",
        "    language = \"language\"\n",
        "    feminism = \"feminism\"\n",
        "    health = \"health\"\n",
        "    media = \"media\"\n",
        "    physics = \"physics\"\n",
        "    culture = \"culture\"\n",
        "    psychology = \"psychology\"\n",
        "    artificial_intelligence = \"artificial-intelligence\"\n",
        "\n",
        "\n",
        "class TaggableItem(BaseModel):\n",
        "    title: str\n",
        "    subtitle: str\n",
        "    tags: List[Tag]\n",
        "\n",
        "\n",
        "class TaggableItems(BaseModel):\n",
        "    items: List[TaggableItem]\n",
        "\n",
        "\n",
        "tagged_items = llm(\n",
        "    TaggableItems,\n",
        "    f\"Tag the following items with the appropriate tags. Options: {json.dumps([tag.value for tag in Tag])}\",\n",
        "    json.dumps(items),\n",
        ")\n",
        "\n",
        "pd.DataFrame([\n",
        "  {\"title\": item.title, \"subtitle\": item.subtitle, \"tags\": ' '.join(item.tags)}\n",
        "  for item in tagged_items.items\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clustering\n",
        "\n",
        "Now that we have classified out items and assigned a tag to each of them, we might want to cluster them together, based on their content and the tags assigned. One of the advantages of using an LLM to complete this task (rather than a predictive model), is that the LLM can also explain the choices it made, for example by giving each cluster a title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_clusters = 5\n",
        "\n",
        "class TaggableItemsCluster(BaseModel):\n",
        "    title: str\n",
        "    items: List[TaggableItem]\n",
        "\n",
        "class TaggableItemsClusters(BaseModel):\n",
        "    clusters: List[TaggableItemsCluster]\n",
        "\n",
        "tagged_items_clusters = llm(\n",
        "    TaggableItemsClusters,\n",
        "    f\"Cluster the following items based on their tags and content. Create exactly {num_clusters} clusters.\",\n",
        "    json.dumps(tagged_items.dict()[\"items\"]),\n",
        ")\n",
        "\n",
        "clusters = []\n",
        "for cluster in tagged_items_clusters.clusters:\n",
        "  for item in cluster.items:\n",
        "    clusters.append({\"cluster\": cluster.title, \"title\": item.title, \"subtitle\": item.subtitle, \"tags\": ' '.join(item.tags)})\n",
        "pd.DataFrame(clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic Data Generation\n",
        "\n",
        "They used to say that \"data is the new oil\". That valuable! What if we found an endless supply of data to work with? LLMs are great at generating new texts and pieces of information. That can be very useful in many data science and ML projects, as we can use the LLM to generate synthetic data for us.\n",
        "\n",
        "Let's try using the LLM to generate some test data for exercising a sentiment analysis system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SyntheticSentiment(BaseModel):\n",
        "    sentiment: str = Field(..., description=\"A review about food.\")\n",
        "    rating: int\n",
        "\n",
        "sentiment = llm(\n",
        "    SyntheticSentiment,\n",
        "    \"Generate food review with sentiments within a spectrum of sentiments, with rating between 1 and 5.\",\n",
        "    temperature= 0.5\n",
        ")\n",
        "\n",
        "print_result(sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's easy. Now let's generate multiple examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Rating(str, Enum):\n",
        "    poor = \"*\"\n",
        "    average = \"**\"\n",
        "    good = \"***\"\n",
        "    great = \"****\"\n",
        "    outstanding = \"*****\"\n",
        "\n",
        "class SyntheticSentiment(BaseModel):\n",
        "    sentiment: str = Field(..., description=\"A generated review about food.\")\n",
        "    rating: str = Field(...,description=\"rating of food review between 1 and 5\")\n",
        "\n",
        "class SyntheticSentiments(BaseModel):\n",
        "    sentiments: List[SyntheticSentiment]\n",
        "\n",
        "n = 10\n",
        "\n",
        "sentiments = llm(\n",
        "    SyntheticSentiments,\n",
        "    f\"Generate {n} food review with sentiments within a spectrum of sentiments in sorted order from most negative to positive, with rating. : {json.dumps([rating for rating in Rating])}\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "pd.DataFrame(sentiments.dict()[\"sentiments\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbTVEz9kQry"
      },
      "source": [
        "## Planning and Tool-Use\n",
        "\n",
        "Complex systems and behaviours often need to plan multiple steps ahead and interact with the \"world\". LLMs can often do that quite well. Let's look at a couple of examples.\n",
        "\n",
        "If our LLM knows of a distinct set of actions it can take, we can get it to plan which actions to perform and in what order, based on the relevant situation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Action(str, Enum):\n",
        "  WAKE_UP = \"Wake up\"\n",
        "  TURN_OFF_ALARM = \"Turn off the alarm\"\n",
        "  STRETCH = \"Stretch\"\n",
        "  GET_OUT_OF_BED = \"Get out of bed\"\n",
        "  USE_BATHROOM = \"Use the bathroom\"\n",
        "  CHECK_FOR_MOVIE_SNACKS = \"Check for movie snacks\"\n",
        "  WASH_FACE_EVENING = \"Wash face in the evening\"\n",
        "  CHANGE_INTO_PYJAMAS = \"Change into pyjamas\"\n",
        "  SET_ALARM_FOR_NEXT_DAY = \"Set alarm for the next day\"\n",
        "  CHECK_PHONE_FOR_MESSAGES = \"Check phone for messages\"\n",
        "  TURN_OFF_LIGHTS = \"Turn off lights\"\n",
        "  WALK_OR_DRIVE_TO_MOVIE_THEATRE = \"Walk or drive to the movie theatre\"\n",
        "  USE_BATHROOM_EVENING = \"Use the bathroom in the evening\"\n",
        "  DRY_OFF_WITH_TOWEL = \"Dry off with a towel\"\n",
        "  BRUSH_TEETH = \"Brush teeth\"\n",
        "  WASH_FACE = \"Wash face\"\n",
        "  SHOWER = \"Take a shower\"\n",
        "  GRAB_WALLET_PURSE = \"Grab wallet or purse\"\n",
        "  MAKE_SURE_PHONE_IS_CHARGED = \"Make sure phone is charged\"\n",
        "  CALL_A_TAXI_ARRANGE_TRANSPORTATION = \"Call a taxi or arrange transportation\"\n",
        "  MEET_FRIENDS_AT_DESIGNATED_PLACE = \"Meet friends at designated place\"\n",
        "  LEAVE_THE_HOUSE = \"Leave the house\"\n",
        "  PLAN_TO_BUY_AT_THEATRE = \"Plan to buy tickets at the theatre\"\n",
        "  DECIDE_ON_MEETING_PLACE_AND_TIME = \"Decide on meeting place and time\"\n",
        "  GET_DRESSED = \"Get dressed\"\n",
        "  APPLY_DEODORANT = \"Apply deodorant\"\n",
        "  COMB_BRUSH_HAIR = \"Comb or brush hair\"\n",
        "  STYLE_HAIR = \"Style hair\"\n",
        "  SHAVE = \"Shave\"\n",
        "  PUT_ON_CLOTHES = \"Put on clothes\"\n",
        "  APPLY_MAKEUP = \"Apply makeup\"\n",
        "  PREPARE_BREAKFAST = \"Prepare breakfast\"\n",
        "  EAT_BREAKFAST = \"Eat breakfast\"\n",
        "  MAKE_COFFEE_TEA = \"Make coffee or tea\"\n",
        "  CHECK_PHONE_FOR_MESSAGES_EMAILS = \"Check phone for messages or emails\"\n",
        "  PACK_LUNCH = \"Pack lunch\"\n",
        "  GATHER_WORK_MATERIALS = \"Gather work materials\"\n",
        "  PUT_ON_SHOES = \"Put on shoes\"\n",
        "  GRAB_KEYS = \"Grab keys\"\n",
        "  PURCHASE_TICKETS_AT_THEATRE = \"Purchase tickets at the theatre\"\n",
        "  LOCK_THE_DOOR = \"Lock the door\"\n",
        "  FINISH_DINNER = \"Finish dinner\"\n",
        "  CLEAN_UP_DINNER_DISHES = \"Clean up dinner dishes\"\n",
        "  WATCH_TV_READ_BOOK = \"Watch TV or read a book\"\n",
        "  BRUSH_TEETH_EVENING = \"Brush teeth in the evening\"\n",
        "  GET_INTO_BED = \"Get into bed\"\n",
        "  MEDITATE_RELAX = \"Meditate or relax\"\n",
        "  WRITE_IN_JOURNAL = \"Write in journal\"\n",
        "  LISTEN_TO_CALMING_MUSIC = \"Listen to calming music\"\n",
        "  TURN_OFF_ELECTRONIC_DEVICES = \"Turn off electronic devices\"\n",
        "  ADJUST_PILLOWS_AND_BLANKETS = \"Adjust pillows and blankets\"\n",
        "  READ_BOOK = \"Read a book\"\n",
        "  CLOSE_EYES_TRY_TO_SLEEP = \"Close eyes and try to sleep\"\n",
        "  DECIDE_ON_MOVIE_TO_WATCH = \"Decide on a movie to watch\"\n",
        "  CHECK_MOVIE_TIMES_ONLINE = \"Check movie times online\"\n",
        "  PURCHASE_TICKETS_ONLINE = \"Purchase tickets online\"\n",
        "  BUY_SNACKS_AT_CONCESSION_STAND = \"Buy snacks at the concession stand\"\n",
        "  FIND_CORRECT_THEATRE_SCREEN = \"Find the correct theatre screen\"\n",
        "  FIND_SEATS = \"Find seats\"\n",
        "  WATCH_THE_MOVIE = \"Watch the movie\"\n",
        "  DISCUSS_MOVIE_WITH_FRIENDS = \"Discuss the movie with friends\"\n",
        "  SAY_GOODBYE_TO_FRIENDS = \"Say goodbye to friends\"\n",
        "  RETURN_HOME = \"Return home\"\n",
        "\n",
        "activities = [\n",
        "  \"Waking up and going to work\",\n",
        "  \"Winding down and going to sleep\",\n",
        "  \"Going to see a movie with friends\",\n",
        "]\n",
        "\n",
        "class ActionSequence(BaseModel):\n",
        "  actions: List[Action]\n",
        "\n",
        "for activity in activities:\n",
        "  action_sequence = llm(\n",
        "      ActionSequence,\n",
        "      \"Generate a sequence of actions for the user-provided activity.\",\n",
        "      activity,\n",
        "  )\n",
        "  print(f\"Activity: {activity}\")\n",
        "  for index, action in enumerate(action_sequence.actions, start=1):\n",
        "    print(f\"{index}. {action.value}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our final example, let's get our LLM act as a game-playing engine. The game is simple, tic-tac-toe (that's a simple example, but the best LLMs have been shown capable of playing much more complex games). We can get a lot of behaviour with very little programming, just by asking the LLM and restricting the input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TicTacToeMove(BaseModel):\n",
        "  row: int\n",
        "  col: int\n",
        "\n",
        "class TicTacToeStrategy(str, Enum):\n",
        "  optimal = \"Optimal. Always choose the best move for winning the game or preventing your opponent from winning.\"\n",
        "  random = \"Random. Choose your next move at random.\"\n",
        "  next_free = \"Next Freee. Always choose the next free spot counting from the top-left.\"\n",
        "\n",
        "class TicTacToeWinner(str, Enum):\n",
        "  X = \"X\"\n",
        "  O = \"O\"\n",
        "  Tie = \"Tie\"\n",
        "  Ongoing = \"Ongoing\"\n",
        "\n",
        "class TicTacToeStatus(BaseModel):\n",
        "  winner: TicTacToeWinner\n",
        "\n",
        "class TicTacToeBoard:\n",
        "  def __init__(self):\n",
        "    self.board = [[' ' for _ in range(3)] for _ in range(3)]\n",
        "  \n",
        "  def dumps_board(self):\n",
        "    return '\\n-----\\n'.join(['|'.join(row) for row in self.board]) + '\\n'\n",
        "\n",
        "  def print_board(self):\n",
        "    print(self.dumps_board())\n",
        "  \n",
        "  def make_move(self, role, move: TicTacToeMove):\n",
        "    self.board[move.row][move.col] = role\n",
        "  \n",
        "  def check_status(self) -> TicTacToeWinner:\n",
        "    return llm(\n",
        "        TicTacToeStatus,\n",
        "        (\"Check the status and whether there is a winner in this game of Tic-Tac-Toe. \" +\n",
        "         \"The options are: X - X won, O - O won, \" +\n",
        "         \"Tie - there are no more possible moves and it's a tie, \" +\n",
        "         \"Ongoing - there are still empty slots on the board.\"),\n",
        "        self.dumps_board(),\n",
        "    ).winner\n",
        "\n",
        "class TicTacToePlayer:\n",
        "  def __init__(self, role, strategy):\n",
        "    self.role = role\n",
        "    self.strategy = strategy\n",
        "\n",
        "  def turn(self, board):\n",
        "    move = llm(\n",
        "        TicTacToeMove,\n",
        "        (\"You are a Tic-Tac-Toe Player. \" +\n",
        "         f\"Your role is: {self.role}. It's your turn. \" +\n",
        "         f\"Your strategy is: {self.strategy}. \"\n",
        "         \"Look at the board and announce your move.\"),\n",
        "        board.dumps_board(),\n",
        "    )\n",
        "    board.make_move(self.role, move)\n",
        "    board.print_board()\n",
        "\n",
        "board = TicTacToeBoard()\n",
        "player_x = TicTacToePlayer('X', TicTacToeStrategy.optimal)\n",
        "player_o = TicTacToePlayer('O', TicTacToeStrategy.next_free)\n",
        "\n",
        "next_player = player_x\n",
        "while board.check_status() == TicTacToeWinner.Ongoing:\n",
        "  next_player.turn(board)\n",
        "  next_player = player_x if next_player == player_o else player_o\n",
        "\n",
        "print(f\"Game Over! Winner: {board.check_status()}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
