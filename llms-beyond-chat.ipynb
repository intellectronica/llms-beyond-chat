{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-zWHmskQru"
      },
      "source": [
        "## Setting Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRxzoZEYkQrv"
      },
      "source": [
        "### Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5hLfrJGkQrw"
      },
      "outputs": [],
      "source": [
        "%pip install openai pydantic instructor python-dotenv\n",
        "from IPython.display import clear_output ; clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVV6MCRIkQrw"
      },
      "source": [
        "### Loading Azure Open AI configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d2dCRzUxkQrx"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "GPT_4_O_MODEL_NAME = os.getenv(\"GPT_4_O_MODEL_NAME\", default=\"gpt-4o\")\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "aoai = AzureOpenAI(\n",
        "    api_version=\"2024-05-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FAs_fKkQrx"
      },
      "source": [
        "## Using Structured Input/Output with OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "client = instructor.from_openai(aoai)\n",
        "\n",
        "def print_json(data):\n",
        "    print(json.dumps(data, indent=2))\n",
        "\n",
        "def print_schema(model: BaseModel):\n",
        "    print_json(model.model_json_schema(), indent=2)\n",
        "\n",
        "def print_result(result: BaseModel):\n",
        "    print(result.model_dump_json(indent=2))\n",
        "\n",
        "def llm(response_model: BaseModel = BaseModel, system: str = None, user: str = None):\n",
        "    messages = []\n",
        "    if system:\n",
        "        messages.append({\"role\": \"system\", \"content\": system})\n",
        "    if user:\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "    result = client.chat.completions.create(\n",
        "        model=GPT_4_O_MODEL_NAME,\n",
        "        response_model=response_model,\n",
        "        messages=messages,\n",
        "    )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9xib4jBkQrx",
        "outputId": "31c103a7-60d5-4d34-818d-479ddcffbd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"properties\": {\n",
            "    \"first_name\": {\n",
            "      \"title\": \"First Name\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"last_name\": {\n",
            "      \"title\": \"Last Name\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"street\": {\n",
            "      \"title\": \"Street\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"house_number\": {\n",
            "      \"title\": \"House Number\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"postal_code\": {\n",
            "      \"title\": \"Postal Code\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"city\": {\n",
            "      \"title\": \"City\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"state\": {\n",
            "      \"title\": \"State\",\n",
            "      \"type\": \"string\"\n",
            "    },\n",
            "    \"country\": {\n",
            "      \"title\": \"Country\",\n",
            "      \"type\": \"string\"\n",
            "    }\n",
            "  },\n",
            "  \"required\": [\n",
            "    \"first_name\",\n",
            "    \"last_name\",\n",
            "    \"street\",\n",
            "    \"house_number\",\n",
            "    \"postal_code\",\n",
            "    \"city\",\n",
            "    \"state\",\n",
            "    \"country\"\n",
            "  ],\n",
            "  \"title\": \"AddressInfo\",\n",
            "  \"type\": \"object\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "class AddressInfo(BaseModel):\n",
        "    first_name: str\n",
        "    last_name: str\n",
        "    street: str\n",
        "    house_number: str\n",
        "    postal_code: str\n",
        "    city: str\n",
        "    state: str\n",
        "    country: str\n",
        "\n",
        "print_schema(AddressInfo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"first_name\": \"Eleanor\",\n",
            "  \"last_name\": \"Berger\",\n",
            "  \"street\": \"Freilagerstrasse\",\n",
            "  \"house_number\": \"97\",\n",
            "  \"postal_code\": \"8047\",\n",
            "  \"city\": \"Zürich\",\n",
            "  \"state\": \"Zürich\",\n",
            "  \"country\": \"Switzerland\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "address_info = llm(\n",
        "    AddressInfo,\n",
        "    \"Eleanor Berger lives in Switzerland, in the canton of Zürich. Her home is at Freilagerstrasse 97, 8047 Zürich.\"\n",
        ")\n",
        "\n",
        "print_result(address_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQBHip4rkQry"
      },
      "source": [
        "## Working with Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translation and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_language='de' translation='Language skills are an important part of communication.'\n"
          ]
        }
      ],
      "source": [
        "class TranslatedString(BaseModel):\n",
        "    input_language: str = Field(..., description=\"The language of the original text, as 2-letter language code.\")\n",
        "    translation: str\n",
        "\n",
        "translation = llm(\n",
        "    TranslatedString,\n",
        "    \"Detect the language of the original text and translate it into English.\",\n",
        "    \"Sprachkenntnisse sind ein wichtiger Bestandteil der Kommunikation.\",\n",
        ")\n",
        "\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"translations\": [\n",
            "    {\n",
            "      \"language\": \"de\",\n",
            "      \"translation\": \"Große Sprachmodelle sind ein mächtiges Werkzeug für die Verarbeitung natürlicher Sprache.\"\n",
            "    },\n",
            "    {\n",
            "      \"language\": \"fr\",\n",
            "      \"translation\": \"Les grands modèles de langage sont un outil puissant pour le traitement du langage naturel.\"\n",
            "    },\n",
            "    {\n",
            "      \"language\": \"it\",\n",
            "      \"translation\": \"I modelli linguistici di grandi dimensioni sono uno strumento potente per l'elaborazione del linguaggio naturale.\"\n",
            "    },\n",
            "    {\n",
            "      \"language\": \"es\",\n",
            "      \"translation\": \"Los grandes modelos de lenguaje son una herramienta poderosa para el procesamiento del lenguaje natural.\"\n",
            "    },\n",
            "    {\n",
            "      \"language\": \"he\",\n",
            "      \"translation\": \"מודלים של שפה גדולים הם כלי עוצמתי לעיבוד שפה טבעית.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "class Translation(BaseModel):\n",
        "    language: str = Field(..., description=\"The language of the translated text, as 2-letter language code.\")\n",
        "    translation: str\n",
        "\n",
        "class Translations(BaseModel):\n",
        "    translations: List[Translation]\n",
        "\n",
        "target_languages = [\"de\", \"fr\", \"it\", \"es\", \"he\"]\n",
        "\n",
        "translations = llm(\n",
        "    Translations,\n",
        "    f\"Translate the user-provided text into the following languages: {json.dumps(target_languages)}\",\n",
        "    \"Large Language Models are a powerful tool for natural language processing.\",\n",
        ")\n",
        "\n",
        "print_result(translations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"normalized_texts\": [\n",
            "    {\n",
            "      \"style\": \"formal\",\n",
            "      \"text\": \"Large Language Models represent a significant advancement in the domain of natural language processing.\"\n",
            "    },\n",
            "    {\n",
            "      \"style\": \"informal\",\n",
            "      \"text\": \"Large Language Models are a really cool tool for getting computers to understand language.\"\n",
            "    },\n",
            "    {\n",
            "      \"style\": \"casual\",\n",
            "      \"text\": \"Those Large Language Models are pretty awesome for handling language processing.\"\n",
            "    },\n",
            "    {\n",
            "      \"style\": \"academic\",\n",
            "      \"text\": \"Large Language Models constitute a substantial development within the field of natural language processing, offering advanced capabilities in understanding and generating human language.\"\n",
            "    },\n",
            "    {\n",
            "      \"style\": \"professional\",\n",
            "      \"text\": \"Large Language Models offer robust solutions for natural language processing tasks, enhancing computational understanding and generation of human language.\"\n",
            "    },\n",
            "    {\n",
            "      \"style\": \"business\",\n",
            "      \"text\": \"Leveraging Large Language Models can significantly improve natural language processing capabilities, providing a competitive edge in automated language understanding and customer engagement.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text_styles = [\"formal\", \"informal\", \"casual\", \"academic\", \"professional\", \"business\"]\n",
        "\n",
        "class NormalizedText(BaseModel):\n",
        "    style: str = Field(\n",
        "        ...,\n",
        "        description=(f\"The style of the text normalization.  Options: {json.dumps(text_styles)}\"))\n",
        "    text: str\n",
        "\n",
        "class NormalizedTexts(BaseModel):\n",
        "    normalized_texts: List[NormalizedText]\n",
        "\n",
        "normalizations = llm(\n",
        "    NormalizedTexts,\n",
        "    f\"Normalize the user-provided text into the following styles: {json.dumps(text_styles)}\",\n",
        "    \"Large Language Models are a powerful tool for natural language processing.\",\n",
        ")\n",
        "\n",
        "print_result(normalizations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYFPu0w7kQry"
      },
      "source": [
        "## Decision Making"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbTVEz9kQry"
      },
      "source": [
        "## Planning and Tool-Use"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
