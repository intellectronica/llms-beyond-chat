{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "â„¹ï¸ **This is the *practice* version of the notebook**, with solutions and outputs ommitted. Use it to complete the tutorial with your own solutions.\n",
        "\n",
        "A version with the complete solutions and outputs is available at [llms-beyond-chat.ipynb](llms-beyond-chat.ipynb).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLMs: Beyond Chat\n",
        "\n",
        "Large Language Models, like GPT-4o, are well known as capabale chatbots, through applications like ChatGPT and Copilot. While chatting with a computer is a magical experience, these models can do some much more than just chat. In this tutorial we'll review some of these capabilities and adopt an approach for working with LLMs that treats them more like an execution engine for software - a VM, if you will - than a chatty persona. We'll use structured input and ouput, relying on typed schema, to interface between the textual and difficult to predict and control world of LLMs and the realm of software development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-zWHmskQru"
      },
      "source": [
        "## Setting Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRxzoZEYkQrv"
      },
      "source": [
        "### Installing Dependencies\n",
        "\n",
        "We'll need the following Python packages:\n",
        "- `python-dotenv` for loading the endpoint configuration from the .env file\n",
        "- `openai` for making calls to Azure Open AI\n",
        "- `pydantic` and `instructor` for using typed, structured input and output with our LLM calls\n",
        "- `pandas`, `matplotlib`, `networkx`, and `jinja2` to help us visualise our output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5hLfrJGkQrw"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv openai pydantic instructor pandas matplotlib networkx jinja2\n",
        "# from IPython.display import clear_output ; clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVV6MCRIkQrw"
      },
      "source": [
        "### Loading Azure Open AI configuration\n",
        "\n",
        "To configure your Azure Open AI GPT-4o endpoint:\n",
        "1. Create a deployment of GPT-4o in one of the [available regions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#public-cloud-regions). Use a \"Global Standard\" deployment to get the best performance. If you prefer to use an earlier model like GPT-4-turbo you can use that too (but it will be slower and more expensive).\n",
        "2. Copy the file `dot.env` to `.env`. Edit it and update the values for `AZURE_OPENAI_ENDPOINT`,`AZURE_OPENAI_API_KEY`, and `GPT_4_O_MODEL_NAME` (that's your deployment name).\n",
        "3. The next cell will load these values and configure the OpenAI SDK to use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2dCRzUxkQrx"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "GPT_4_O_MODEL_NAME = os.getenv(\"GPT_4_O_MODEL_NAME\", default=\"gpt-4o\")\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "aoai = AzureOpenAI(\n",
        "    api_version=\"2024-05-01-preview\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FAs_fKkQrx"
      },
      "source": [
        "## Using Structured Input/Output with OpenAI\n",
        "\n",
        "To use typed, structured input and output with our LLM calls, we will be relying on `pydantic` and `instructor`.\n",
        "\n",
        "**Pydantic** ( [https://docs.pydantic.dev/](https://docs.pydantic.dev/) ) is a popular package for extending Python's typing system with declerative interfaces.\n",
        "\n",
        "**Instructor** ( [https://python.useinstructor.com/](https://python.useinstructor.com/) ) patches the LLM SDK with the ability to use a Pydantic model for specifying the JSON schema for the LLM output, and parsing the result into the Pydantic mode. We will be using it in all of our examples to interact with our LLM.\n",
        "\n",
        "Let's start by patching our LLM client and defining some helper functions..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "import json\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# `client` is a patched Open AI SDK client that allows passing a Pydantic\n",
        "# model for specifying the schema and parsing the output.\n",
        "client = instructor.from_openai(aoai)\n",
        "\n",
        "# Let's define a helper function for calling the LLM. We will use this\n",
        "# function for all our LLM calls.\n",
        "def llm(response_model: BaseModel = BaseModel, system: str = None,\n",
        "        user: str = None, temperature: float = 0.0, max_tokens: int = 1000):\n",
        "    \"\"\"\n",
        "    Helper function for calling the LLM (GPT-4o) with a Pydantic BaseModel,\n",
        "    a system prompt and/or a user prompt, with temperature and max_tokens.\n",
        "    \"\"\"\n",
        "    messages = []\n",
        "    if system:\n",
        "        messages.append({\"role\": \"system\", \"content\": system})\n",
        "    if user:\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "    result = client.chat.completions.create(\n",
        "        model=GPT_4_O_MODEL_NAME,\n",
        "        response_model=response_model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return result\n",
        "\n",
        "def print_schema(model: BaseModel):\n",
        "    \"\"\"\n",
        "    Print the JSON schema corrsponding to a Pydantic model.\n",
        "    \"\"\"\n",
        "    print(json.dumps(model.model_json_schema(), indent=2))\n",
        "\n",
        "def print_result(result: BaseModel):\n",
        "    \"\"\"\n",
        "    Print the Pydantic model result of an LLM call as JSON.\n",
        "    \"\"\"\n",
        "    print(result.model_dump_json(indent=2))\n",
        "\n",
        "# Configure Pandas to format dataframes for pretty output inside the notebook\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.DataFrame._repr_html_ = lambda df: df.style.set_properties(**{'text-align': 'left'})._repr_html_()\n",
        "\n",
        "def visualize_graph(graph):\n",
        "    \"\"\"\n",
        "    Visualize a graph.\n",
        "    Expects a graph object with `nodes` and `edges` properties,\n",
        "    where each node has an `id`, `label`, and `color`\n",
        "    and each edge has `source`, `target`, `label`, and `color`.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    for node in graph.nodes:\n",
        "        G.add_node(node.id, label=node.label, color=node.color)\n",
        "    for edge in graph.edges:\n",
        "        G.add_edge(edge.source, edge.target, label=edge.label, color=edge.color)\n",
        "    pos = nx.planar_layout(G)\n",
        "    node_colors = [node[1]['color'] for node in G.nodes(data=True)]\n",
        "    edge_colors = [edge[2]['color'] for edge in G.edges(data=True)]\n",
        "    labels = {node[0]: node[1]['label'] for node in G.nodes(data=True)}\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    nx.draw(G, pos, labels=labels, with_labels=True, node_color=node_colors, edge_color=edge_colors, font_size=8)\n",
        "    plt.title(\"Knowledge Graph\")\n",
        "    plt.show()\n",
        "\n",
        "def print_tree(data, indent=0):\n",
        "    \"\"\"\n",
        "    Pretty-print a JSON object as a tree.\n",
        "    \"\"\"\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            print('   ' * indent + key.upper() + ':')\n",
        "            print_tree(value, indent + 1)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            print_tree(item, indent)\n",
        "    else:\n",
        "        print('   ' * indent + str(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQBHip4rkQry"
      },
      "source": [
        "## Working with Text\n",
        "\n",
        "LLMs are master text manipulators. If it's reading or writing text, the best LLMs can do amazing things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translation and Normalization\n",
        "\n",
        "Reading and writing, understanding and translating text between languages, or language styles, is an easy task with LLMs.\n",
        "\n",
        "Let's start by reading a sentence in one language, detecting which language it is, and translating the sentence to English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "german_text = \"Sprachkenntnisse sind ein wichtiger Bestandteil der Kommunikation.\"\n",
        "\n",
        "class TranslatedString(BaseModel):\n",
        "    input_language: str = Field(\n",
        "        ...,\n",
        "        description=\"The language of the original text, as 2-letter language code.\"\n",
        "    )\n",
        "    translation: str\n",
        "\n",
        "print(\"SCHEMA:\")\n",
        "print_schema(TranslatedString)\n",
        "\n",
        "translation = llm(\n",
        "    TranslatedString,\n",
        "    \"Detect the language of the original text and translate it into English.\",\n",
        "    german_text,\n",
        ")\n",
        "\n",
        "print(\"RESULT:\")\n",
        "print_result(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our LLM can cope with a more complex task. Let's get it to translate the same sentence to multiple languages.\n",
        "\n",
        "Comment on token selection: for many processing tasks we'd want the LLM to be quite conservative with token selection, to get the most accurate results, but when it comes to writing text, it is often better to give it more freedom in selecting tokens from a wider distribution. We can control that by passing a higher `temperature` value when making the call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "english_text = \"Large Language Models are a powerful tool for natural language processing.\"\n",
        "\n",
        "class TargetLanguage(str, Enum):\n",
        "    de = \"de\"\n",
        "    fr = \"fr\"\n",
        "    it = \"it\"\n",
        "    es = \"es\"\n",
        "    he = \"he\"\n",
        "\n",
        "class Translation(BaseModel):\n",
        "    language: TargetLanguage = Field(\n",
        "        ...,\n",
        "        description=\"The language of the translated text, as 2-letter language code.\"\n",
        "    )\n",
        "    translation: str\n",
        "\n",
        "class Translations(BaseModel):\n",
        "    translations: List[Translation]\n",
        "\n",
        "print_schema(Translations)\n",
        "\n",
        "translations = llm(\n",
        "    Translations,\n",
        "    (\"Translate the user-provided text into the following languages: \" +\n",
        "     json.dumps([language.value for language in TargetLanguage])),\n",
        "    english_text,\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "pd.DataFrame(translations.dict()[\"translations\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as we can translate to different languages, we can also use the format to rewrite text in a different style or tone within the same language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = \"Large Language Models are a powerful tool for natural language processing.\"\n",
        "\n",
        "class TextStyle(str, Enum):\n",
        "    formal = \"formal\"\n",
        "    informal = \"informal\"\n",
        "    casual = \"casual\"\n",
        "    academic = \"academic\"\n",
        "    professional = \"professional\"\n",
        "    business = \"business\"\n",
        "\n",
        "# PRACTICE: Using a similar technique as above, get the LLM to format the input_text\n",
        "# in all the styles listed in TextStyle and output the results as a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unstructured Data\n",
        "\n",
        "One very powerful task we can use an LLM for, is parsing unstructured information into a data structure. Addresses, for example, are often found in documents in incosistent formats, and parsing them into a consistent data strcuture can be very useful for using them in a software system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9xib4jBkQrx",
        "outputId": "31c103a7-60d5-4d34-818d-479ddcffbd37"
      },
      "outputs": [],
      "source": [
        "address_str = (\n",
        "    \"Sherlock Holmes lives in the United Kingdom. \"\n",
        "    \"His residence is in at 221B Baker Street, London, NW1 6XE.\"\n",
        ")\n",
        "\n",
        "class AddressInfo(BaseModel):\n",
        "    first_name: str\n",
        "    last_name: str\n",
        "    street: str\n",
        "    house_number: str\n",
        "    postal_code: str\n",
        "    city: str\n",
        "    state: str\n",
        "    country: str\n",
        "\n",
        "address_info = llm(\n",
        "    AddressInfo,\n",
        "    address_str,\n",
        ")\n",
        "\n",
        "print_result(address_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That was easy! We didn't even have to prompt, just let the LLM know what is the data structure we are expecting. How about a more complex input with multiple addresses? We should be able to get the LLM to process that too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = (\n",
        "  \"During my recent travels, I had the pleasure of visiting several fascinating locations. \"\n",
        "  \"My journey began at the office of Dr. Elena Martinez, 142B Elm Street, San Francisco, \"\n",
        "  \"CA 94107, USA. Her office, nestled in the bustling heart of the city, was a hub of \"\n",
        "  \"innovation and creativity. Next, I made my way to the historic residence of Mr. Hans \"\n",
        "  \"Gruber located at 3. Stock, Goethestrasse 22, 8001 ZÃ¼rich, Switzerland. The old building, \"\n",
        "  \"with its classic Swiss architecture, stood as a testament to the cityâ€™s rich cultural \"\n",
        "  \"heritage. My adventure continued at the tranquil countryside home of Satoshi Nakamoto, \"\n",
        "  \"2-15-5, Sakura-cho, Musashino-shi, Tokyo-to 180-0003, Japan. Their home was surrounded by \"\n",
        "  \"beautiful cherry blossoms, creating a picturesque scene straight out of a postcard. In \"\n",
        "  \"Europe, I visited the charming villa of Mme. Catherine Dubois, 15 Rue de la RÃ©publique, \"\n",
        "  \"69002 Lyon, France. The cobblestone streets and historic buildings of Lyon provided a \"\n",
        "  \"perfect backdrop to her elegant home. Finally, my journey concluded at the modern apartment \"\n",
        "  \"of Mr. David Johnson, Apt 7B, 34 Queen Street, Toronto, ON M5H 2Y4, Canada. The sleek \"\n",
        "  \"design of the apartment building mirrored the contemporary vibe of the city itself.\"\n",
        "  )\n",
        "\n",
        "# PRACTICE: Use the LLM to extract all the addresses from input_text\n",
        "# and output the results as a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The intelligence of LLMs allows them to \"understand\" complex logical and hierarchical structures. Consider the task of converting some information into a knowledge graph. Turning longform text into structure we can work with as part of a system can be of great value, and our LLM can help us achieve that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = (\n",
        "    \"Some products are edible and others are inedible. Soap, newspapers, and shoes, for example, \"\n",
        "    \"are inedible. Of the products that are edible, some are sweet and others are savory. \"\n",
        "    \"Chocolate, candy, and ice cream are sweet, while pizza, burgers, and fries are savory. \"\n",
        "    \"Chocolate comes in different forms, such as milk chocolate, dark chocolate, and white chocolate. \"\n",
        "    \"The New York Times, The Wall Street Journal, and The Washington Post are newspapers.\"\n",
        ")\n",
        "\n",
        "# PRACTICE: Use the LLM to format the information in input_text as a knowledge graph.\n",
        "# You can visualize the graph using the `visualize_graph` function - it expects a graph object\n",
        "# with `nodes` and `edges` properties, where each node has an `id`, `label`, and `color`\n",
        "# and each edge has `source`, `target`, `label`, and `color`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some structures are recursive. Consider the task of parsing a linguistic sentence into a grammatical tree structure. This NLP task has kept computational linguists busy for decades, often with limited success. LLMs, however, are quite good at this sort of thing. Let's try to get the LLM to parse a simple sentence into a simplified tree grammar of English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_str = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# PRACTICE: Use the LLM to parse input_str into a simple grammar tree,\n",
        "# made of Verb Phrases, Noun Phrases, Prepositional Phrases, etc.\n",
        "# If you visualize the tree using the `print_tree` function, it might\n",
        "# look something like this:\n",
        "# NOUN:\n",
        "#    DET:\n",
        "#       the\n",
        "#    ADJ:\n",
        "#       quick\n",
        "#       brown\n",
        "#    NOUN:\n",
        "#       fox\n",
        "# VERB:\n",
        "#    jumps\n",
        "# PREP:\n",
        "#    PREP:\n",
        "#       over\n",
        "#    NOUN:\n",
        "#       DET:\n",
        "#          the\n",
        "#       ADJ:\n",
        "#          lazy\n",
        "#       NOUN:\n",
        "#          dog\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ’¡ What other cases do you know where parsing unstructured information from text into data structures is a useful application? Could you automate any process that is currently performed manually by giving the task to an LLM? ... Some models (like GPT-4o) can also read images as input ... how about using a photo or scan as the input and parsing it into structured data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic Data Generation\n",
        "\n",
        "They used to say that \"data is the new oil\". That valuable! What if we found an endless supply of data to work with? LLMs are great at generating new texts and pieces of information. That can be very useful in many data science and ML projects, as we can use the LLM to generate synthetic data for us.\n",
        "\n",
        "Let's try using the LLM to generate some test data for exercising a sentiment analysis system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SyntheticSentiment(BaseModel):\n",
        "    sentiment: str = Field(..., description=\"A review about food.\")\n",
        "    rating: int\n",
        "\n",
        "sentiment = llm(\n",
        "    SyntheticSentiment,\n",
        "    \"Generate food review with sentiments within a spectrum of sentiments, with rating between 1 and 5.\",\n",
        "    temperature= 0.5\n",
        ")\n",
        "\n",
        "print_result(sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's easy. Now let's generate multiple examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Rating(str, Enum):\n",
        "    poor = \"*\"\n",
        "    average = \"**\"\n",
        "    good = \"***\"\n",
        "    great = \"****\"\n",
        "    outstanding = \"*****\"\n",
        "\n",
        "n = 10\n",
        "\n",
        "# PRACTICE: Use the LLM to generate `n` synthetic food reviews with ratings\n",
        "# within the spectrum of sentiments, and ratings between 1 and 5.\n",
        "# Output the results as a table, sorted by rating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ’¡ Where can you use unlimited amount of test data, conforming to strict ranges and structures? What projects or tests can you run if collecting a data set is as trivial as calling an LLM?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYFPu0w7kQry"
      },
      "source": [
        "## Decision Making\n",
        "\n",
        "We've looked at LLMs reading and, in a way, \"understanding\" information, and rewriting it in useful formats. But the best LLMs also exhibit limited, but nevertheless impressive, reasoning and decision-making capabilities. Let's see how we can exploit them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sentiment Analysis\n",
        "\n",
        "Sentiment analysis, passing a judgement on the tone of a linguistic statement, is a common task that is being used in many systems, especially ones that are user-facing. Without any additional training, our LLM turns out to be quite good at making these judgements. It even can judge its own confidence level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_texts = [\n",
        "    \"I am very happy with the service provided by the company.\",\n",
        "    \"The food was terrible and the service was slow.\",\n",
        "    \"The movie was okay.\",\n",
        "    \"The weather is perfect for a day at the beach.\",\n",
        "    \"I am mostly satisfied with the product, but there are a few issues.\",\n",
        "    \"The experience was note quite what I have expected.\",\n",
        "    \"Butterflies are often colourful, and they can fly.\",\n",
        "]\n",
        "\n",
        "class Sentiment(str, Enum):\n",
        "    positive = \"positive\"\n",
        "    negative = \"negative\"\n",
        "    neutral = \"neutral\"\n",
        "\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    sentiment: Sentiment\n",
        "    confidence: float\n",
        "\n",
        "# PRACTICE: Use the LLM to analyze the sentiment of the example_texts\n",
        "# and output the results as a table, with each text, sentiment, and confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification\n",
        "\n",
        "Classification is another task that requires judgement. We want our take several pieces of content and assign them to a class, or multiple tags. We want the LLM to take out taxonomy into consideration, but also make a descision as to which tags would best fit every item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "items = [\n",
        "    {\"title\": \"The Great Gatsby\", \"subtitle\": \"A novel by F. Scott Fitzgerald\"},\n",
        "    {\"title\": \"The Theory of Relativity\", \"subtitle\": \"A scientific theory by Albert Einstein\"},\n",
        "    {\"title\": \"The Technology and Culture of Ancient Rome\", \"subtitle\": \"A cross-disciplinary study of ancient Rome\"},\n",
        "    {\"title\": \"Football on Television\", \"subtitle\": \"The technology and cultural impact of televising football games\"},\n",
        "    {\"title\": \"The Philosophy of Taylor Swift\", \"subtitle\": \"A philosophical analysis of the music and lyrics of Taylor Swift\"},\n",
        "    {\"title\": \"The Spanish Language in popular music\", \"subtitle\": \"A review of the use of the Spanish language in popular music\"},\n",
        "    {\"title\": \"The Impact of Artificial Intelligence on Healthcare\", \"subtitle\": \"Exploring the role of AI in revolutionizing healthcare\"},\n",
        "    {\"title\": \"The History of Jazz Music\", \"subtitle\": \"Tracing the origins and evolution of jazz music\"},\n",
        "    {\"title\": \"The Rise of E-commerce in the Digital Age\", \"subtitle\": \"Examining the growth and impact of online shopping\"},\n",
        "    {\"title\": \"The Art of Photography\", \"subtitle\": \"Exploring the creative and technical aspects of photography\"},\n",
        "    {\"title\": \"The Psychology of Decision Making\", \"subtitle\": \"Understanding the cognitive processes behind decision making\"},\n",
        "    {\"title\": \"The Role of Women in STEM Fields\", \"subtitle\": \"Highlighting the contributions of women in science, technology, engineering, and mathematics\"},\n",
        "    {\"title\": \"The Cultural Significance of Tattoos\", \"subtitle\": \"Exploring the history and symbolism of tattoos in different cultures\"},\n",
        "]\n",
        "\n",
        "\n",
        "class Tag(str, Enum):\n",
        "    literature = \"literature\"\n",
        "    science = \"science\"\n",
        "    history = \"history\"\n",
        "    technology = \"technology\"\n",
        "    art = \"art\"\n",
        "    music = \"music\"\n",
        "    sports = \"sports\"\n",
        "    philosophy = \"philosophy\"\n",
        "    language = \"language\"\n",
        "    feminism = \"feminism\"\n",
        "    health = \"health\"\n",
        "    media = \"media\"\n",
        "    physics = \"physics\"\n",
        "    culture = \"culture\"\n",
        "    psychology = \"psychology\"\n",
        "    artificial_intelligence = \"artificial-intelligence\"\n",
        "\n",
        "# PRACTICE: Use the LLM to generate tags for the items in the list above.\n",
        "# The tags should be selected from the Tag enum, and should correspond to the\n",
        "# content of the item. Output the results as a table.\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clustering\n",
        "\n",
        "Now that we have classified out items and assigned a tag to each of them, we might want to cluster them together, based on their content and the tags assigned. One of the advantages of using an LLM to complete this task (rather than a predictive model), is that the LLM can also explain the choices it made, for example by giving each cluster a title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_clusters = 5\n",
        "\n",
        "# PRACTICE: Use the LLM to cluster the items in the list above into `num_clusters`.\n",
        "# Each cluster should have a title, to help us explain why the LLM made that grouping\n",
        "# choice. Output the results as a table with cluster, title, subtitle, and tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ’¡ What other use-cases can you think of where simple decision-making can be handed off to an LLM? Can you think of examples where you'd be OK with letting the LLM make some decisions without human inspection? How will you know if the accuracy is good enough?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbTVEz9kQry"
      },
      "source": [
        "## Planning and Tool-Use\n",
        "\n",
        "Complex systems and behaviours often need to plan multiple steps ahead and interact with the \"world\". LLMs can often do that quite well. Let's look at a couple of examples.\n",
        "\n",
        "If our LLM knows of a distinct set of actions it can take, we can get it to plan which actions to perform and in what order, based on the relevant situation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Action(str, Enum):\n",
        "  WAKE_UP = \"Wake up\"\n",
        "  TURN_OFF_ALARM = \"Turn off the alarm\"\n",
        "  STRETCH = \"Stretch\"\n",
        "  GET_OUT_OF_BED = \"Get out of bed\"\n",
        "  USE_BATHROOM = \"Use the bathroom\"\n",
        "  CHECK_FOR_MOVIE_SNACKS = \"Check for movie snacks\"\n",
        "  WASH_FACE_EVENING = \"Wash face in the evening\"\n",
        "  CHANGE_INTO_PYJAMAS = \"Change into pyjamas\"\n",
        "  SET_ALARM_FOR_NEXT_DAY = \"Set alarm for the next day\"\n",
        "  CHECK_PHONE_FOR_MESSAGES = \"Check phone for messages\"\n",
        "  TURN_OFF_LIGHTS = \"Turn off lights\"\n",
        "  WALK_OR_DRIVE_TO_MOVIE_THEATRE = \"Walk or drive to the movie theatre\"\n",
        "  USE_BATHROOM_EVENING = \"Use the bathroom in the evening\"\n",
        "  DRY_OFF_WITH_TOWEL = \"Dry off with a towel\"\n",
        "  BRUSH_TEETH = \"Brush teeth\"\n",
        "  WASH_FACE = \"Wash face\"\n",
        "  SHOWER = \"Take a shower\"\n",
        "  GRAB_WALLET_PURSE = \"Grab wallet or purse\"\n",
        "  MAKE_SURE_PHONE_IS_CHARGED = \"Make sure phone is charged\"\n",
        "  CALL_A_TAXI_ARRANGE_TRANSPORTATION = \"Call a taxi or arrange transportation\"\n",
        "  MEET_FRIENDS_AT_DESIGNATED_PLACE = \"Meet friends at designated place\"\n",
        "  LEAVE_THE_HOUSE = \"Leave the house\"\n",
        "  PLAN_TO_BUY_AT_THEATRE = \"Plan to buy tickets at the theatre\"\n",
        "  DECIDE_ON_MEETING_PLACE_AND_TIME = \"Decide on meeting place and time\"\n",
        "  GET_DRESSED = \"Get dressed\"\n",
        "  APPLY_DEODORANT = \"Apply deodorant\"\n",
        "  COMB_BRUSH_HAIR = \"Comb or brush hair\"\n",
        "  STYLE_HAIR = \"Style hair\"\n",
        "  SHAVE = \"Shave\"\n",
        "  PUT_ON_CLOTHES = \"Put on clothes\"\n",
        "  APPLY_MAKEUP = \"Apply makeup\"\n",
        "  PREPARE_BREAKFAST = \"Prepare breakfast\"\n",
        "  EAT_BREAKFAST = \"Eat breakfast\"\n",
        "  MAKE_COFFEE_TEA = \"Make coffee or tea\"\n",
        "  CHECK_PHONE_FOR_MESSAGES_EMAILS = \"Check phone for messages or emails\"\n",
        "  PACK_LUNCH = \"Pack lunch\"\n",
        "  GATHER_WORK_MATERIALS = \"Gather work materials\"\n",
        "  PUT_ON_SHOES = \"Put on shoes\"\n",
        "  GRAB_KEYS = \"Grab keys\"\n",
        "  PURCHASE_TICKETS_AT_THEATRE = \"Purchase tickets at the theatre\"\n",
        "  LOCK_THE_DOOR = \"Lock the door\"\n",
        "  FINISH_DINNER = \"Finish dinner\"\n",
        "  CLEAN_UP_DINNER_DISHES = \"Clean up dinner dishes\"\n",
        "  WATCH_TV_READ_BOOK = \"Watch TV or read a book\"\n",
        "  BRUSH_TEETH_EVENING = \"Brush teeth in the evening\"\n",
        "  GET_INTO_BED = \"Get into bed\"\n",
        "  MEDITATE_RELAX = \"Meditate or relax\"\n",
        "  WRITE_IN_JOURNAL = \"Write in journal\"\n",
        "  LISTEN_TO_CALMING_MUSIC = \"Listen to calming music\"\n",
        "  TURN_OFF_ELECTRONIC_DEVICES = \"Turn off electronic devices\"\n",
        "  ADJUST_PILLOWS_AND_BLANKETS = \"Adjust pillows and blankets\"\n",
        "  READ_BOOK = \"Read a book\"\n",
        "  CLOSE_EYES_TRY_TO_SLEEP = \"Close eyes and try to sleep\"\n",
        "  DECIDE_ON_MOVIE_TO_WATCH = \"Decide on a movie to watch\"\n",
        "  CHECK_MOVIE_TIMES_ONLINE = \"Check movie times online\"\n",
        "  PURCHASE_TICKETS_ONLINE = \"Purchase tickets online\"\n",
        "  BUY_SNACKS_AT_CONCESSION_STAND = \"Buy snacks at the concession stand\"\n",
        "  FIND_CORRECT_THEATRE_SCREEN = \"Find the correct theatre screen\"\n",
        "  FIND_SEATS = \"Find seats\"\n",
        "  WATCH_THE_MOVIE = \"Watch the movie\"\n",
        "  DISCUSS_MOVIE_WITH_FRIENDS = \"Discuss the movie with friends\"\n",
        "  SAY_GOODBYE_TO_FRIENDS = \"Say goodbye to friends\"\n",
        "  RETURN_HOME = \"Return home\"\n",
        "\n",
        "activities = [\n",
        "  \"Waking up and going to work\",\n",
        "  \"Winding down and going to sleep\",\n",
        "  \"Going to see a movie with friends\",\n",
        "]\n",
        "\n",
        "# PRACTICE: Use the LLM to generate a sequence of actions for each of the activities,\n",
        "# based on the actions available in the enum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our final example, let's get our LLM act as a game-playing engine. The game is simple, tic-tac-toe (that's a simple example, but the best LLMs have been shown capable of playing much more complex games). We can get a lot of behaviour with very little programming, just by asking the LLM and restricting the input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TicTacToeMove(BaseModel):\n",
        "  row: int\n",
        "  col: int\n",
        "\n",
        "class TicTacToeStrategy(str, Enum):\n",
        "  optimal = \"Optimal. Always choose the best move for winning the game or preventing your opponent from winning.\"\n",
        "  random = \"Random. Choose your next move at random.\"\n",
        "  next_free = \"Next Freee. Always choose the next free spot counting from the top-left.\"\n",
        "\n",
        "class TicTacToeWinner(str, Enum):\n",
        "  X = \"X\"\n",
        "  O = \"O\"\n",
        "  Tie = \"Tie\"\n",
        "  Ongoing = \"Ongoing\"\n",
        "\n",
        "class TicTacToeStatus(BaseModel):\n",
        "  winner: TicTacToeWinner\n",
        "\n",
        "class TicTacToeBoard:\n",
        "  def __init__(self):\n",
        "    self.board = [[' ' for _ in range(3)] for _ in range(3)]\n",
        "  \n",
        "  def dumps_board(self):\n",
        "    return '\\n-----\\n'.join(['|'.join(row) for row in self.board]) + '\\n'\n",
        "\n",
        "  def print_board(self):\n",
        "    print(self.dumps_board())\n",
        "  \n",
        "  def make_move(self, role, move: TicTacToeMove):\n",
        "    self.board[move.row][move.col] = role\n",
        "  \n",
        "  def check_status(self) -> TicTacToeWinner:\n",
        "    pass # PRACTICE: Use the LLM to implement the logic to check the status\n",
        "    # of the game and return the winner.\n",
        "    # TIP: consider how many tokens you need for the solution. Even if the output\n",
        "    # is limited to a schema, the LLM may be tempted to use all the token budget\n",
        "    # to \"think out loud\" about the solution, but that might not be necessary for\n",
        "    # such a simple game.\n",
        "\n",
        "class TicTacToePlayer:\n",
        "  def __init__(self, role, strategy):\n",
        "    self.role = role\n",
        "    self.strategy = strategy\n",
        "\n",
        "  def turn(self, board):\n",
        "    move = # PRACTICE: Use the LLM to generate the next move based on the\n",
        "    # player's role and strategy and the state of the game board.\n",
        "\n",
        "    board.make_move(self.role, move)\n",
        "    board.print_board()\n",
        "\n",
        "board = TicTacToeBoard()\n",
        "player_x = TicTacToePlayer('X', TicTacToeStrategy.optimal)\n",
        "player_o = TicTacToePlayer('O', TicTacToeStrategy.next_free)\n",
        "\n",
        "next_player = player_x\n",
        "while board.check_status() == TicTacToeWinner.Ongoing:\n",
        "  next_player.turn(board)\n",
        "  next_player = player_x if next_player == player_o else player_o\n",
        "\n",
        "print(f\"Game Over! Winner: {board.check_status()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ’¡ Can you think of more demanding tasks you could automate by connecting an LLM to the \"real world\"? How can you structure the interface between the LLM and external \"tools\"? How will you validate that the LLM's decisions are optimal, or at least ensure that you can recover from sub-optimal decisions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion - Your LLM is a VM\n",
        "\n",
        "In this tutorial we explored simple ways of using an LLM as software device. One that gets programmed with instructions in human language, but also understands and respects software interfaces. These examples may seem trivial, but the best LLMs, like GPT-4o, can handle a lot more complexity, and perform with quite a lot of \"intelligence\". Now that you're familiar with this way of thinking about LLMs, and with some techniques for interfacing with an LLM from your software, what will you build?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
